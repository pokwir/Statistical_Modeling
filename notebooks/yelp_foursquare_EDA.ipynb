{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pybikes\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import copy\n",
    "import os\n",
    "import scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up for success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read City Bike dataframe from csv store in a temporary dataframe referreed to here as 'data'\n",
    "data = pd.read_csv('City_Bike.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lat-lon column for use in API requests\n",
    "data['ll'] = data['latitude'].astype(str) + ',' + data['longitude'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a deep copy that we can modify, incase something fails we can evert back to the original dataframe\n",
    "df = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foursquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to Foursquare with a small radius (1000m) for all the bike stations in your city of choice. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> setting up for success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get latitute - longitude from city bike dataframe for use in the the python fucntion we are going to be using\n",
    "location = df.ll.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that takes in a list of cordinates as an argument, sends request to four square and returns a dataframe\n",
    "# with list of points of intrest per coordinate\n",
    "def locate_point_of_I(some_list):\n",
    "    '''function that takes in a list of cordinates as an argument, sends request to four square and returns a dataframe\n",
    "# with list of points of intrest per coordinate'''\n",
    "    list_of_places = []\n",
    "    for ll1 in some_list: \n",
    "# get request\n",
    "        url = f'https://api.foursquare.com/v3/places/search?query=Bar&ll={ll1}&radius=1000&fields=fsq_id%2Cname%2Clocation%2Ccategories%2Cpopularity%2Cprice%2Crating&sort=POPULARITY'\n",
    "        #api_key = os.environ[\"FOURSQUARE_API_KEY\"]\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"Authorization\": 'fsq3zWaQ/44fYj08FZtEaJdlElEGfyy/K44oZt8FMGs1YIg='\n",
    "                }\n",
    "# Parse through the response to get the POI \n",
    "        response = requests.get(url, headers=headers).json()\n",
    "#iterate through response and pass response for the following parameters to a pandas df\n",
    "        for poi in response['results']:\n",
    "            categories = poi.get('categories', None)\n",
    "            cat_id = categories[0]['id'] if len(categories) > 0 else None\n",
    "            category_name = categories[0]['name'] if len(categories) > 0 else None\n",
    "\n",
    "            places = {\n",
    "                'll': f'{ll1}'\n",
    "                , 'fsq_id': poi['fsq_id']\n",
    "                , 'cat_id': cat_id\n",
    "                , 'category_name': category_name\n",
    "                , 'categories': categories\n",
    "                , 'name': poi.get('name', None)\n",
    "                , 'address': poi.get('location', {}).get('formatted_address', None)\n",
    "                , 'city': poi.get('location', {}).get('locality', None)\n",
    "                , 'country': poi.get('location', {}).get('country', None)\n",
    "                , 'rating': poi.get('rating', None)\n",
    "                , 'popularity': poi.get('popularity', None)\n",
    "                , 'price': poi.get('price', None)\n",
    "\n",
    "            }\n",
    "            list_of_places.append(places)\n",
    "    return pd.DataFrame(list_of_places)\n",
    "# return list_of_places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the POI (such as restaurants, bars, etc) details you want (ratings, name, location, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step is already included in the function above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe for foursquare here reffered to as dataf\n",
    "# doing this by calling the 'locate_point_of_I' function and passing in the location list (coordinates from the city_bike data frame) \n",
    "dataf = pd.DataFrame(locate_point_of_I(some_list = location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean copy\n",
    "FourSquare_df = copy.deepcopy(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Dataframe to CSV\n",
    "FourSquare_df.to_csv('FourSquare_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a request to Yelp with a small radius (1000m) for all the bike stations in your city of choice. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> setting up for success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set API key\n",
    "YelpAPI = os.environ.get('YELPAPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of indexes, latitudes, and longitudes from bike stations to be used in the python program\n",
    "\n",
    "bike_stations_for_yelp = df.loc[:,['latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index range from city bike dataframe\n",
    "bike_station_index = range(0,234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse through the response to get the POI (such as restaurants, bars, etc) details you want (ratings, name, location, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function that will take a dataframe formatted with columns as index, latitude and longitude\n",
    "def get_yelp_poi(data_frame_index):\n",
    "    '''function that connects to yelp API, queries the api and returns a pandas dataframe with details like price, rating, etc for points of interest on Yelp'''\n",
    "    list_of_places = []\n",
    "\n",
    "    #loop that goes through the indexes and returns lat and lon to be used in the body of the function\n",
    "    for index in data_frame_index:\n",
    "            lat = bike_stations_for_yelp.iloc[index,0]\n",
    "            lon = bike_stations_for_yelp.iloc[index,1]\n",
    "            \n",
    "            url = f'https://api.yelp.com/v3/businesses/search?latitude={lat}&longitude={lon}&radius=500&categories=Bar&categories=Resturant&categories=Coffee&categories=Park&price=1&price=2&price=3&price=4&fields=id%2Cname%2Coordinates%2Ctransactions%2Ccategories%2Clocation%2Cprice%2Crating%2Creview_count&sort=review_count'\n",
    "            key = YelpAPI\n",
    "            headers = {\n",
    "                \"accept\": \"application/json\",\n",
    "                'Authorization' : YelpAPI\n",
    "            }\n",
    "        \n",
    "        # get request    \n",
    "            response = requests.get(url, headers=headers).json()\n",
    "\n",
    "        # define varriables in the json that i need\n",
    "            print (response) # so i can see whats bring populated\n",
    "            for poi in response['businesses']:\n",
    "                    categories = poi['categories'][0] if len(poi['categories']) > 0 else None\n",
    "                    category_name = poi['categories'][0].get('title') if len(categories) > 0 else None\n",
    "                    business_id = poi.get('id') if len(categories) > 0 else None\n",
    "                    business_name = poi.get('name') if len(categories) > 0 else poi.get('alias')\n",
    "                    try: \n",
    "                        price_value = len(poi.get('price'))\n",
    "                    except: \n",
    "                        price_value = 0\n",
    "\n",
    "        #columns to be populated \n",
    "                    places = {\n",
    "                        'lat': f'{lat}'\n",
    "                        ,'lat': f'{lon}'\n",
    "                        , 'business_id': business_id\n",
    "                        , 'category_name': category_name\n",
    "                        #, 'categories': categories\n",
    "                        , 'name': business_name\n",
    "                        , 'address': poi.get('location', {}).get('display_address', None)\n",
    "                        , 'city': poi.get('location', {}).get('city', None)\n",
    "                        , 'state': poi.get('location', {}).get('state', None)\n",
    "                        , 'country': poi.get('location', {}).get('country', None)\n",
    "                        , 'transactions': poi.get('transactions', None)\n",
    "                        , 'reviews': poi.get('review_count', None)\n",
    "                        , 'rating': poi.get('rating', None)\n",
    "                        , 'price_scale': price_value\n",
    "                        , 'price': poi.get('price', None)\n",
    "                        , 'distance_4rm_bike' : round(poi.get('distance'))\n",
    "                    }\n",
    "                    list_of_places.append(places)\n",
    "    return pd.DataFrame(list_of_places)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your parsed results into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe by calling the 'get_yelp_poi' function and pass bike station index as a argument\n",
    "\n",
    "df_yelp = pd.DataFrame(get_yelp_poi(data_frame_index = bike_station_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy so we can revert back to original dataframe if an error occurs\n",
    "Yelp_df = copy.deepcopy(df_yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expoort dataframe to CSV \n",
    "Yelp_df.to_csv('Yelp_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which API provided you with more complete data? Provide an explanation. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Overall the yelp dataframe is more rich - more observations, and additional data like price rating, reviews and no null/ nan values (seems yelp put alot of effort into maintaining the api but also judging from the doccumentation and different types of querries you can do). This is especially important depending on the use case of the data. If further analysis is going to be done like conducting regression modeling, rich data is important and having to drop/ fill for a large number of observations is taxing, but might also introduce alot of bias or noise in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the top 10 restaurants according to their rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four Square\n",
    "dataf.sort_values(by=['rating'])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yelp\n",
    "Yelp_df.sort_values(by=['rating'])[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
